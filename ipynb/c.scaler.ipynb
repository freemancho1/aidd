{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import aidd.sys.config as cfg\n",
    "from aidd.utils.data_io import read_data, save_data\n",
    "from aidd.utils.data_io import read_pickle, save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaling:\n",
    "    def __init__(self, pdf=None):\n",
    "        self.df = read_data('PP,SL', dtype={'CONS_ID': str}) if pdf is None else pdf\n",
    "        self.data = {}\n",
    "        self.sdata = {}\n",
    "        self._run()\n",
    "        \n",
    "    def _run(self):\n",
    "        self._split_Xy()\n",
    "        for pc in cfg.DATA_PC_TYPE[1:]:\n",
    "            self._split_pc(pc_mode=pc)\n",
    "        for pc in cfg.DATA_PC_TYPE:\n",
    "            self._split_train_test(pc_mode=pc)\n",
    "        self._scaling()\n",
    "        \n",
    "    def _split_Xy(self):\n",
    "        df = self.df\n",
    "        \n",
    "        # TARGET 컬럼 지정\n",
    "        target_col = 'TOTAL_CONS_COST'\n",
    "        # 학습 컬럼 지정\n",
    "        training_cols = df.columns[5:].tolist()\n",
    "        # X, y값 분리\n",
    "        X = df[training_cols].copy()\n",
    "        y = df[target_col].copy()\n",
    "        print(f'학습대상 속성 전체 크기: {X.shape}')\n",
    "        \n",
    "        self.data['X_ALL'] = X\n",
    "        self.data['y_ALL'] = y\n",
    "        \n",
    "        # 학습 데이터 저장\n",
    "        save_data(X, file_code='SCALING,X,ALL')\n",
    "        save_data(y, file_code='SCALING,y,ALL')\n",
    "        \n",
    "    def _split_pc(self, pc_mode='1'):\n",
    "        _X = self.data['X_ALL']\n",
    "        _y = self.data['y_ALL']\n",
    "        \n",
    "        if pc_mode == '1':\n",
    "            conditions = _X.POLE_CNT == 1\n",
    "            X, y = _X[conditions], _y[conditions]\n",
    "        else:\n",
    "            conditions = _X.POLE_CNT != 1\n",
    "            X, y = _X[conditions], _y[conditions]\n",
    "        print(f'PC_MODE[{pc_mode}] X Size: {X.shape}')\n",
    "        \n",
    "        self.data[f'X_{pc_mode}'] = X\n",
    "        self.data[f'y_{pc_mode}'] = y\n",
    "        \n",
    "        # 학습 데이터 저장\n",
    "        save_data(X, file_code=f'SCALING,X,{pc_mode}')\n",
    "        save_data(y, file_code=f'SCALING,y,{pc_mode}')\n",
    "    \n",
    "    def _split_train_test(self, pc_mode='ALL'):\n",
    "        X = self.data[f'X_{pc_mode}']\n",
    "        y = self.data[f'y_{pc_mode}']\n",
    "        \n",
    "        train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "        msg = f'PC_MODE[{pc_mode}] Total{X.shape}, Train{train_X.shape}, ' \\\n",
    "              f'Test{test_X.shape}'\n",
    "        print(msg)\n",
    "        self.data[f'TRAIN_X_{pc_mode}'] = train_X\n",
    "        self.data[f'TRAIN_y_{pc_mode}'] = train_y\n",
    "        self.data[f'TEST_X_{pc_mode}'] = test_X\n",
    "        self.data[f'TEST_y_{pc_mode}'] = test_y\n",
    "        \n",
    "    def _scaling(self):\n",
    "        for pc in cfg.DATA_PC_TYPE:\n",
    "            self._scaling_main(pc_mode=pc)\n",
    "            \n",
    "    def _scaling_main(self, pc_mode='ALL'):\n",
    "        train_X = self.data[f'TRAIN_X_{pc_mode}']\n",
    "        test_X = self.data[f'TEST_X_{pc_mode}']\n",
    "        \n",
    "        cols = train_X.columns.tolist()\n",
    "        scaler = StandardScaler()\n",
    "        train_sX = scaler.fit_transform(train_X)\n",
    "        test_sX = scaler.transform(test_X)\n",
    "\n",
    "        train_sX_df = pd.DataFrame(train_sX, columns=cols)\n",
    "        test_sX_df = pd.DataFrame(test_sX, columns=cols)\n",
    "        \n",
    "        # 클래스에 저장\n",
    "        self.sdata[f'TRAIN_X_{pc_mode}'] = train_sX_df\n",
    "        self.sdata[f'TRAIN_y_{pc_mode}'] = self.data[f'TRAIN_y_{pc_mode}']\n",
    "        self.sdata[f'TEST_X_{pc_mode}'] = train_sX_df\n",
    "        self.sdata[f'TEST_y_{pc_mode}'] = self.data[f'TEST_y_{pc_mode}']\n",
    "        \n",
    "        # 이 부분은 굳이 저장할 필요가 있나 싶음\n",
    "        save_data(train_sX_df, file_code=f'SCALING,TRAIN_X,{pc_mode}')\n",
    "        save_data(self.data[f'TRAIN_y_{pc_mode}'], f'SCALING,TRAIN_y,{pc_mode}')\n",
    "        save_data(test_sX_df, file_code=f'SCALING,TEST_X,{pc_mode}')\n",
    "        save_data(self.data[f'TEST_y_{pc_mode}'], f'SCALING,TEST_y,{pc_mode}')\n",
    "        \n",
    "        # 스케일러 저장\n",
    "        save_pickle(scaler, file_code=f'DUMP,SCALER,{pc_mode}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습대상 속성 전체 크기: (14729, 105)\n",
      "PC_MODE[1] X Size: (8750, 105)\n",
      "PC_MODE[N1] X Size: (5979, 105)\n",
      "PC_MODE[ALL] Total(14729, 105), Train(11783, 105), Test(2946, 105)\n",
      "PC_MODE[1] Total(8750, 105), Train(7000, 105), Test(1750, 105)\n",
      "PC_MODE[N1] Total(5979, 105), Train(4783, 105), Test(1196, 105)\n"
     ]
    }
   ],
   "source": [
    "batch_scaling = Scaling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t213p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
