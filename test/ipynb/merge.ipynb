{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 개요\n",
    "학습용 또는 온라인 시험용을 생성한 샘플 데이터를 전처리에 사용할 수 있도록 공사비 단위로 하나의 레코드로 취합하는 역할을 수행\n",
    "* 온라인/배치 부분이 구분되어 구현되 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 진행사항\n",
    "* STEP01: 각 데이터 셋에서 학습대상 레코드와 컬럼 추출\n",
    "  * 이 부분은 온라인과 배치 부분이 상반되기 때문에 별도로 구현함\n",
    "* STEP02: 공사비별 전주/전선/인입선 갯 수 계산 및 체크\n",
    "* STEP03: 하나의 데이터프레임으로 취합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "import aidd.sys.config as cfg\n",
    "from aidd.sys.utils import Logs, AiddException\n",
    "from aidd.batch.data_manager import get_provide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77f93b305b7f][2024-03-13 21:43:27.251539] 제공받은 데이터 불러오기 시작\n",
      "[77f93b305b7f][2024-03-13 21:43:46.003953]   읽은 데이터: CONS, 데이터 크기: (19052, 143), 처리시간: 0:00:18.752343\n",
      "[77f93b305b7f][2024-03-13 21:44:03.071932]   읽은 데이터: POLE, 데이터 크기: (38533, 63), 처리시간: 0:00:17.067903\n",
      "[77f93b305b7f][2024-03-13 21:44:24.958423]   읽은 데이터: LINE, 데이터 크기: (40019, 77), 처리시간: 0:00:21.886411\n",
      "[77f93b305b7f][2024-03-13 21:44:34.030185]   읽은 데이터: SL, 데이터 크기: (22632, 57), 처리시간: 0:00:09.071686\n",
      "[77f93b305b7f][2024-03-13 21:44:34.030253] 제공받은 데이터 불러오기 종료, 최종 처리시간: 0:01:06.778730\n"
     ]
    }
   ],
   "source": [
    "pdata = get_provide_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP01: 각 데이터 셋에서 학습대상 레코드와 컬럼 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 배치 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONS: (15335, 8)\n",
      "POLE: (27896, 6)\n",
      "LINE: (30348, 11)\n",
      "SL: (17034, 6)\n"
     ]
    }
   ],
   "source": [
    "# 모델에 사용할 데이터 딕셔너리\n",
    "batch_dict = {}\n",
    "\n",
    "# 공사비 데이터 학습대상 레코드/컬럼 추출\n",
    "key = 'CONS'\n",
    "df = pdata[key]\n",
    "# (전주/전선 수를 제외한) 공사비 데이터 부분에서 학습 대상 레코드 조건\n",
    "# * 접수종류명(ACC_TYPE_NAME), 계약전력(CONT_CAP),\n",
    "# * 공사형태코드(CONS_TYPE_CD), 총공사비(TOTAL_CONS_COST)\n",
    "modeling_records = \\\n",
    "    (df.ACC_TYPE_NAME == cfg.COND_ACC_TYPE_NAME) & \\\n",
    "    (df.CONT_CAP < cfg.COND_MAX_CONT_CAP) & \\\n",
    "    (df.CONS_TYPE_CD == cfg.COND_CONS_TYPE_CD) & \\\n",
    "    (df.TOTAL_CONS_COST < cfg.COND_MAX_TOTAL_CONS_COST)\n",
    "df = df[modeling_records].reset_index(drop=True)\n",
    "cons_df = df[cfg.MODELING_COLS[key]]\n",
    "batch_dict[key] = cons_df\n",
    "\n",
    "# 전주/전선/인입선 데이터 학습대상 레코드/컬럼 추출\n",
    "# * 레크도는 공사비에 있는 공사번호를 대상으로 함\n",
    "for key in cfg.DATA_TYPE[1:]:\n",
    "    df = pdata[key]\n",
    "    df = df[df.CONS_ID.isin(cons_df.CONS_ID)]\n",
    "    batch_dict[key] = df[cfg.MODELING_COLS[key]]\n",
    "    \n",
    "# (참조용)데이터 셋 별 공사대상 레코드/컬럼 크기 확인\n",
    "for key in cfg.DATA_TYPE:\n",
    "    print(f'{key}: {batch_dict[key].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 온라인 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_online_sample(data):\n",
    "    \"\"\"온라인 서비스 샘플 데이터 생성 함수\n",
    "    * 온라인 서비스나 온라인 서비스를 위한 전처리 프로세스 테스트를 위한\n",
    "      샘플 데이터를 생성하는 함수로, 대상 데이터는 `config`에 지정되어 있음\n",
    "    * 실제 온라인 작업에선 사용하지 않음\n",
    "    Args:\n",
    "        data (dict): 학습용으로 제공받은 전체 데이터\n",
    "            - `key: df`로 구성된 딕셔너리로 제공됨\n",
    "    Returns:\n",
    "        jsons (dict): Online으로 받을 예정인 JSON 데이터의 딕셔너리\n",
    "    \"\"\"\n",
    "    # 전체 데이터에서 샘플 데이터만 추출한 데이터프레임 딕셔너리\n",
    "    jsons = {}\n",
    "    for key in cfg.DATA_TYPE:\n",
    "        df = data[key]\n",
    "        df = df[df.CONS_ID.isin(cfg.CHECK_CONS_IDS)]\n",
    "        # 공사비 데이터셋에 있는 총공사비를 제거하는 코드(3줄이나 소요됨;;)\n",
    "        modeling_cols = cfg.MODELING_COLS[key]\n",
    "        if 'TOTAL_CONS_COST' in modeling_cols:\n",
    "            modeling_cols.remove('TOTAL_CONS_COST')\n",
    "        jsons[key] = df[modeling_cols].to_json(orient='records')\n",
    "        \n",
    "    return jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONS: (3, 8)\n",
      "POLE: (9, 6)\n",
      "LINE: (9, 11)\n",
      "SL: (3, 6)\n"
     ]
    }
   ],
   "source": [
    "json_dict = get_online_sample(data=pdata)\n",
    "\n",
    "# 이 부분은 추후에 수정할 사항이 많아 보임\n",
    "# RESTful로 입력받은 json데이터를 데이터프레임으로 변환\n",
    "\n",
    "# 입력된 데이터를 데이터프레임으로 변환한 딕셔너리\n",
    "# 모델에 사용할 데이터 딕셔너리\n",
    "online_dict = {}\n",
    "for key in json_dict.keys():\n",
    "    online_dict[key] = pd.read_json(StringIO(json_dict[key]))\n",
    "# 총공사비가 없는 경우에는 총공사비 컬럼을 0으로 추가\n",
    "# 예측해야할 값이긴 하지만 온라인/배치 전처리를 같은 함수로 하기 위해 \n",
    "# 컬럼만 추가함\n",
    "if 'TOTAL_CONS_COST' not in online_dict['CONS'].keys():\n",
    "    online_dict['CONS']['TOTAL_CONS_COST'] = 0\n",
    "    \n",
    "# (참조용)데이터 셋 별 공사대상 레코드/컬럼 크기 확인\n",
    "for key in cfg.DATA_TYPE:\n",
    "    print(f'{key}: {online_dict[key].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP02~3: 하나의 클래스로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergingSourceData():\n",
    "    \"\"\"\" 4개의 데이터프레임 취합\n",
    "        CONS, POLE, LINE, SL 데이터를 하나로 묶는 작업을 하며,\n",
    "        CONS의 공사번호별로 POLE, LINE, SL의 카운트는 계산하지만\n",
    "        컬럼 추가작업이나 스케일링 등은 여기서 처리하지 않음\n",
    "    \"\"\"\n",
    "    def __init__(self, pdata=None, is_batch=True):\n",
    "        self._logs = Logs('BATCH_MERGE')\n",
    "        self.pdata = pdata\n",
    "        self.is_batch = is_batch\n",
    "        self.merge_df = None\n",
    "        self._run()\n",
    "        return self.merge_df\n",
    "    \n",
    "    def _run(self):\n",
    "        self._compute_and_check_facilities_count()\n",
    "        \n",
    "    def _compute_and_check_facilities_count(self):\n",
    "        \"\"\" 공사번호별 전주/전선/인입선 갯 수 및 10개 이하만 추출\n",
    "        \"\"\"\n",
    "        mdf = self.pdata[cfg.DATA_TYPE[0]]\n",
    "        for key in cfg.DATA_TYPE[1:]:\n",
    "            count_cons_ids = mdf.CONS_ID.value_counts()\n",
    "            col_name = f'{key}_CNT'\n",
    "            mdf = pd.merge(\n",
    "                mdf, count_cons_ids.rename(col_name),\n",
    "                left_on='CONS_ID', right_on=count_cons_ids.index, how='left'\n",
    "            )\n",
    "            # 해당 공사번호에 없는 설비는 NaN처리되며, 이 값을 0으로 변경\n",
    "            mdf[col_name].fillna(0, inplace=True)  \n",
    "        self._logs.mid('BEFORE_DEL_SIZE', mdf.shape)\n",
    "            \n",
    "        # 모델 학습에 사용할 레코드 추출\n",
    "        # * 전주/전선 갯 수가 10개 이상인 경우 \n",
    "        modeling_records = \\\n",
    "            (mdf.POLE_CNT >= cfg.COND_MIN_POLE_COUNT) & \\\n",
    "            (mdf.POLE_CNT <= cfg.COND_MAX_POLE_COUNT) & \\\n",
    "            (mdf.LINE_CNT >= cfg.COND_MIN_LINE_COUNT) & \\\n",
    "            (mdf.LINE_CNT <= cfg.COND_MAX_LINE_COUNT)\n",
    "        mdf = mdf[modeling_records]\n",
    "                  \n",
    "        self.merge_df = mdf\n",
    "        self._logs.mid('AFTER_DEL_SIZE', mdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 배치 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fcab8fb69402][2024-03-13 21:45:12.699768]   전처리를 위해 제공받은 데이터 병합 시작\n",
      "[fcab8fb69402][2024-03-13 21:45:12.728906]     공사번호별 데이터 병합 결과: (15335, 11)\n",
      "[fcab8fb69402][2024-03-13 21:45:12.730356]     전주/전선 10개 이상 데이터 삭제 후 결과: (15335, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39662/2539130702.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  mdf[col_name].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_39662/2539130702.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  mdf[col_name].fillna(0, inplace=True)\n",
      "/tmp/ipykernel_39662/2539130702.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  mdf[col_name].fillna(0, inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() should return None, not 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_df \u001b[38;5;241m=\u001b[39m \u001b[43mMergingSourceData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() should return None, not 'DataFrame'"
     ]
    }
   ],
   "source": [
    "batch_df = MergingSourceData(batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t213p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
