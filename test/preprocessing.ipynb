{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "import aidd.sys.config as cfg\n",
    "from aidd.sys.utils import Logs\n",
    "from aidd.sys.data_io import read_data, save_data, get_provide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "self = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[099af5b60638][2024-03-25 19:21:39.042099] 제공받은 데이터 불러오기 시작\n",
      "[099af5b60638][2024-03-25 19:21:58.320386]   공사비 데이터 셋: 크기(19052, 143), 처리시간(0:00:19.277932)\n",
      "[099af5b60638][2024-03-25 19:22:15.729633]   전주 데이터 셋: 크기(38533, 63), 처리시간(0:00:17.409167)\n",
      "[099af5b60638][2024-03-25 19:22:37.805040]   전선 데이터 셋: 크기(40019, 77), 처리시간(0:00:22.075322)\n",
      "[099af5b60638][2024-03-25 19:22:46.882370]   인입선 데이터 셋: 크기(22632, 57), 처리시간(0:00:09.077218)\n",
      "[099af5b60638][2024-03-25 19:22:46.882438] 제공받은 데이터 불러오기 종료, 최종 처리시간: 0:01:07.840345\n"
     ]
    }
   ],
   "source": [
    "self.pdict = get_provide_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.is_modeling = True\n",
    "self.ppdict = {}\n",
    "self.ppdf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = cfg.DATA_SETs[0]\n",
    "df = self.pdict[key]\n",
    "# (전주/전선 수를 제외한) 공사비 데이터 부분에서 학습 대상 레코드 조건\n",
    "# * 접수종류명(ACC_TYPE_NAME), 계약전력(CONT_CAP), 총공사비(TOTAL_CONS_COST)\n",
    "modeling_recs = \\\n",
    "    (df.ACC_TYPE_NAME  == cfg.CONSTRAINTs['ACC_TYPE_NAME']) & \\\n",
    "    (df.CONT_CAP        < cfg.CONSTRAINTs['MAX_CONT_CAP']) & \\\n",
    "    (df.TOTAL_CONS_COST < cfg.CONSTRAINTs['MAX_TOTAL_CONS_COST'])\n",
    "    # (df.CONS_TYPE_CD   == cfg.CONSTRAINTs['CONS_TYPE_CD']) & \\\n",
    "df = df[modeling_recs].reset_index(drop=True)\n",
    "cons_df = df[cfg.COLs['PP'][key]['SOURCE']]\n",
    "self.ppdict[key] = cons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15474 entries, 0 to 15473\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   CONS_ID          15474 non-null  object        \n",
      " 1   TOTAL_CONS_COST  15474 non-null  int64         \n",
      " 2   LAST_MOD_DATE    15474 non-null  datetime64[ns]\n",
      " 3   OFFICE_NAME      15474 non-null  object        \n",
      " 4   CONT_CAP         15474 non-null  int64         \n",
      " 5   ACC_TYPE_NAME    15474 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 725.5+ KB\n"
     ]
    }
   ],
   "source": [
    "cons_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28121, 5)\n",
      "(30617, 8)\n",
      "(17222, 5)\n"
     ]
    }
   ],
   "source": [
    "for key in cfg.DATA_SETs[1:]:\n",
    "    df = self.pdict[key]\n",
    "    df = df[df.CONS_ID.isin(cons_df.CONS_ID)]\n",
    "    self.ppdict[key] = df[cfg.COLs['PP'][key]['SOURCE']]\n",
    "    print(self.ppdict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.is_modeling:\n",
    "    # 데이터 저장\n",
    "    for key in cfg.DATA_SETs:\n",
    "        save_data(self.ppdict[key], f'MERGE,BATCH,{key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 'CONS'     # 처리할 데이터 타입(dt)\n",
    "df = self.ppdict[dt]\n",
    "\n",
    "# 결측치 처리\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일자정보 처리\n",
    "# * '최종변경일시'를 이용해 다양한 일자정보 컬럼 추가\n",
    "# * 참고로 일자정보가 날자형식이 아니면 날자형식으로 변환\n",
    "if df.LAST_MOD_DATE.dtype != '<M8[ns]':\n",
    "    df.LAST_MOD_DATE = pd.to_datetime(df.LAST_MOD_DATE)\n",
    "df['YEAR'] = df.LAST_MOD_DATE.dt.year\n",
    "df['MONTH'] = df.LAST_MOD_DATE.dt.month\n",
    "df['DAY'] = df.LAST_MOD_DATE.dt.day\n",
    "df['DAYOFWEEK'] = df.LAST_MOD_DATE.dt.dayofweek\n",
    "df['DAYOFYEAR'] = df.LAST_MOD_DATE.dt.dayofyear\n",
    "df['YEAR_MONTH'] = df.LAST_MOD_DATE.dt.strftime(\"%Y%m\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if self.is_modeling:\n",
    "    offc_list = df.OFFICE_NAME.unique().tolist()\n",
    "    save_data(offc_list, fcode='DUMP,OFFICE_LIST')\n",
    "else:\n",
    "    offc_list = read_data('DUMP,OFFICE_LIST')\n",
    "offc_idxs = []\n",
    "for oname in df.OFFICE_NAME:\n",
    "    offc_idxs.append(offc_list.index(oname))\n",
    "df['OFFICE_NUMBER'] = offc_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15474, 12)\n"
     ]
    }
   ],
   "source": [
    "df = df[cfg.COLs['PP'][dt]['PP']]\n",
    "print(df.shape)\n",
    "self.ppdf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15474 entries, 0 to 15473\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   CONS_ID          15474 non-null  object        \n",
      " 1   TOTAL_CONS_COST  15474 non-null  int64         \n",
      " 2   LAST_MOD_DATE    15474 non-null  datetime64[ns]\n",
      " 3   OFFICE_NAME      15474 non-null  object        \n",
      " 4   CONT_CAP         15474 non-null  int64         \n",
      " 5   YEAR             15474 non-null  int32         \n",
      " 6   MONTH            15474 non-null  int32         \n",
      " 7   DAY              15474 non-null  int32         \n",
      " 8   DAYOFWEEK        15474 non-null  int32         \n",
      " 9   DAYOFYEAR        15474 non-null  int32         \n",
      " 10  YEAR_MONTH       15474 non-null  int64         \n",
      " 11  OFFICE_NUMBER    15474 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int32(5), int64(4), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15474, 15)\n"
     ]
    }
   ],
   "source": [
    "ppdf = self.ppdf\n",
    "# 공사비까지 전처리된 데이터 셋에 설비 갯 수 컬럼 추가(3개)\n",
    "# 공사비 데이터 셋은 처리하지 않아도 됨\n",
    "for key in cfg.DATA_SETs[1:]:\n",
    "    df = self.ppdict[key]\n",
    "    cons_ids_cnt = df.CONS_ID.value_counts()\n",
    "    col_name = f'{key}_CNT'\n",
    "    ppdf = pd.merge(\n",
    "        ppdf, cons_ids_cnt.rename(col_name),\n",
    "        left_on='CONS_ID', right_on=cons_ids_cnt.index, how='left'\n",
    "    )\n",
    "    # 해당 공사번호가 없는 설비는 NaN처리되기 때문에 이 값을 0으로 변경\n",
    "    ppdf[col_name] = ppdf[col_name].fillna(0)\n",
    "print(ppdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14860, 15)\n"
     ]
    }
   ],
   "source": [
    "modeling_recs = \\\n",
    "    (ppdf.POLE_CNT >= cfg.CONSTRAINTs['MIN_POLE_CNT']) & \\\n",
    "    (ppdf.POLE_CNT <= cfg.CONSTRAINTs['MAX_POLE_CNT']) & \\\n",
    "    (ppdf.LINE_CNT >= cfg.CONSTRAINTs['MIN_LINE_CNT']) & \\\n",
    "    (ppdf.LINE_CNT <= cfg.CONSTRAINTs['MAX_LINE_CNT'])    \n",
    "ppdf = ppdf[modeling_recs].reset_index(drop=True)    \n",
    "print(ppdf.shape)\n",
    "\n",
    "self.ppdf = ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 'POLE'     # 처리할 데이터 타입(dt)\n",
    "df = self.ppdict[dt]\n",
    "\n",
    "# 결측치 처리\n",
    "df.fillna(0, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28121, 21)\n"
     ]
    }
   ],
   "source": [
    "# 코드형 컬럼 One-Hot Encoding\n",
    "prefix = ['POLE_SHAPE', 'POLE_TYPE', 'POLE_SPEC']\n",
    "cols = [x+'_CD' for x in prefix]\n",
    "# 숫자형 값 통일(실수형이 아닌 값을 실수형으로 변환)\n",
    "# (One-Hot Encoding시 동일한 컬럼값을 만들기 위해 실행)\n",
    "if df.POLE_SPEC_CD.dtype != 'float64':\n",
    "    df['POLE_SPEC_CD'] = df['POLE_SPEC_CD'].astype(float)\n",
    "df = pd.get_dummies(df, columns=cols, prefix=prefix)\n",
    "# True, False값을 1, 0으로 변환\n",
    "df = df.apply(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "\n",
    "# 실시간 처리에서 동일 컬럼을 추가하기 위해 학습에서 나온 컬럼 리스트 저장\n",
    "df_cols = df.columns.tolist()\n",
    "if self.is_modeling:\n",
    "    save_data(df_cols, fcode='DUMP,POLE_ONE_HOT_COLS')\n",
    "else:\n",
    "    # 학습 당시 컬럼 불러오기\n",
    "    modeling_cols = read_data(fcode='DUMP,POLE_ONE_HOT_COLS')\n",
    "    # 실시간 처리에서 만들어 지지 않는 컬럼 추출\n",
    "    append_cols = [x for x in modeling_cols if x not in df_cols]\n",
    "    # 0으로 컬럼값 추가\n",
    "    df.loc[:, append_cols] = 0\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14860, 34)\n"
     ]
    }
   ],
   "source": [
    "# 공사비별 전주 데이터 합산\n",
    "unique_cons_ids = df.CONS_ID.unique()\n",
    "cons_id_pole_sums = []\n",
    "# 합산대상 컬럼 리스트 추출\n",
    "sum_cols = [col for col in df.columns if col.startswith('POLE_')]\n",
    "# 공사번호별 합산(시간이 좀 걸림, 14700건 처리에 약 40초 소요)\n",
    "for cid in unique_cons_ids:\n",
    "    cons_id_pole_sums.append(\n",
    "        [cid]+df[df.CONS_ID==cid][sum_cols].sum().values.tolist())\n",
    "# 공사번호별로 합산된 전주 정보를 데이터프레임으로 변환\n",
    "pole_sums_df = pd.DataFrame(\n",
    "    cons_id_pole_sums, columns=['CONS_ID'] + sum_cols)\n",
    "\n",
    "# 공사비 데이터와 전주정보 그룹 데이터 병합\n",
    "ppdf = pd.merge(\n",
    "    self.ppdf, pole_sums_df,\n",
    "    left_on='CONS_ID', right_on='CONS_ID', how='left')\n",
    "print(ppdf.shape)\n",
    "\n",
    "self.ppdf = ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e1cd3798799c][2024-03-25 19:24:13.409226] 전선 데이터 전처리 시작\n",
      "[e1cd3798799c][2024-03-25 19:24:13.409888]   전처리 전 전선 데이터 셋 크기: (30617, 8)\n"
     ]
    }
   ],
   "source": [
    "dt = 'LINE'     # 처리할 데이터 타입(dt)\n",
    "logs = Logs(f'PP_{dt}')\n",
    "df = self.ppdict[dt]\n",
    "logs.mid('SOURCE', df.shape)        \n",
    "\n",
    "# 숫자형 값 통일(실수형이 아닌 값을 실수형으로 변환)\n",
    "# (One-Hot Encoding시 동일한 컬럼값을 만들기 위해 실행)\n",
    "if df.LINE_SPEC_CD.dtype != 'float64':\n",
    "    df['LINE_SPEC_CD'] = df['LINE_SPEC_CD'].astype(float)\n",
    "if df.NEUTRAL_SPEC_CD.dtype != 'float64':\n",
    "    df['NEUTRAL_SPEC_CD'] = df['NEUTRAL_SPEC_CD'].astype(float)   \n",
    "# 중성선규격코드(NEUTRAL_SPEC_CD)에 0.0과 NaN이 존재(NaN=>999.0 변환)\n",
    "df['NEUTRAL_SPEC_CD'] = df['NEUTRAL_SPEC_CD'].fillna(999.0)\n",
    "# 중성선종류코드(NEUTRAL_TYPE_CD)의 NaN값을 문자열 'NaN'으로 치환\n",
    "df.NEUTRAL_TYPE_CD = df.NEUTRAL_TYPE_CD.fillna('NaN')\n",
    "# 결선방식이 41인 값이 1개만 존재하기 때문에 많이 있는 43으로 치환\n",
    "df.WIRING_SCHEME = df.WIRING_SCHEME.replace(41, 43)\n",
    "# 전선 전체길이 추가: = 선로길이(SPAN) * 전선 갯 수(PHASE)\n",
    "df.loc[:, 'LINE_LENGTH'] = df.SPAN * df.LINE_PHASE_CD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e1cd3798799c][2024-03-25 19:24:39.393916]   전선 데이터 ONE HOT ENCODING 후 데이터 셋 크기: (30617, 45)\n"
     ]
    }
   ],
   "source": [
    "# 결측치 처리\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# 코드형 컬럼 One-Hot Encoding\n",
    "# WIRING_SCHEME은 마지막에 '_CD'가 붙지 않음\n",
    "prefix = ['WIRING_SCHEME', 'LINE_TYPE', 'LINE_SPEC', 'LINE_PHASE',\n",
    "        'NEUTRAL_TYPE', 'NEUTRAL_SPEC']\n",
    "columns = [x+'_CD' for x in prefix if x != 'WIRING_SCHEME']\n",
    "columns += ['WIRING_SCHEME']\n",
    "df = pd.get_dummies(df, columns=columns, prefix=prefix)\n",
    "# True, False를 1, 0으로 변환\n",
    "df = df.apply(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "# 실시간 처리에서 동일 컬럼을 추가하기 위해 학습에서 나올 컬럼리스트 저장\n",
    "df_cols = df.columns.tolist()\n",
    "if self.is_modeling:\n",
    "    save_data(df_cols, fcode='DUMP,LINE_ONE_HOT_COLS')\n",
    "else:\n",
    "    modeling_cols = read_data(fcode='DUMP,LINE_ONE_HOT_COLS')\n",
    "    append_cols = [col for col in modeling_cols if col not in df_cols]\n",
    "    df.loc[:, append_cols] = 0\n",
    "logs.mid('ONE_HOT', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e1cd3798799c][2024-03-25 19:25:45.841059]   전선 데이터 전처리 후 모델링 데이터 셋 크기: (14860, 75)\n"
     ]
    }
   ],
   "source": [
    "# 공사비별 전선 데이터 합산\n",
    "unique_cons_ids = df.CONS_ID.unique()\n",
    "cons_id_line_sums = []\n",
    "sum_cols = ['SPAN'] + df.columns.tolist()[5:]\n",
    "for cid in unique_cons_ids:\n",
    "    cons_id_line_sums.append(\n",
    "        [cid]+df[df.CONS_ID==cid][sum_cols].sum().values.tolist())\n",
    "# 공사번호별로 합산된 전주 정보를 데이터프레임으로 변환\n",
    "line_sums_df = pd.DataFrame(\n",
    "    cons_id_line_sums, columns=['CONS_ID']+sum_cols)\n",
    "\n",
    "# 공사비 데이터와 전주 그룹 데이터 병합\n",
    "ppdf = pd.merge(\n",
    "    self.ppdf, line_sums_df,\n",
    "    left_on='CONS_ID', right_on='CONS_ID', how='left')\n",
    "logs.mid('RESULT', ppdf.shape)\n",
    "\n",
    "self.ppdf = ppdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[e1cd3798799c][2024-03-25 19:25:45.846589] 전선 데이터 전처리 종료, 최종 처리시간: 0:01:32.437361\n"
     ]
    }
   ],
   "source": [
    "logs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4a8f5736555b][2024-03-25 19:26:00.215885] 인입선 데이터 전처리 시작\n",
      "[4a8f5736555b][2024-03-25 19:26:00.216305]   전처리 전 인입선 데이터 셋 크기: (17222, 5)\n",
      "[4a8f5736555b][2024-03-25 19:26:00.229186]   인입선 데이터 ONE HOT ENCODING 후 데이터 셋 크기: (17222, 29)\n"
     ]
    }
   ],
   "source": [
    "dt = 'SL'     # 처리할 데이터 타입(dt)\n",
    "logs = Logs(f'PP_{dt}')\n",
    "df = self.ppdict[dt]\n",
    "logs.mid('SOURCE', df.shape)    \n",
    "\n",
    "# 숫자형 값 통일(실수형이 아닌 값을 실수형으로 변환)\n",
    "# (One-Hot Encoding시 동일한 컬럼값을 만들기 위해 실행)\n",
    "if df.SL_SPEC_CD.dtype != 'float64':\n",
    "    df['SL_SPEC_CD'] = df['SL_SPEC_CD'].astype(float)\n",
    "# 결측치 처리\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# 코드형 컬럼 One-Hot Encoding\n",
    "prefix = ['SL_TYPE', 'SL_SPEC']\n",
    "columns = [col+'_CD' for col in prefix]\n",
    "df = pd.get_dummies(df, columns=columns, prefix=prefix)\n",
    "df = df.apply(lambda x: int(x) if isinstance(x, bool) else x)\n",
    "# 실시간 처리에서 동일 컬럼을 추가하기 위해 학습에서 나올 컬럼리스트 저장\n",
    "df_cols = df.columns.tolist()\n",
    "if self.is_modeling:\n",
    "    save_data(df_cols, fcode='DUMP,SL_ONE_HOT_COLS')\n",
    "else:\n",
    "    modeling_cols = read_data('DUMP,SL_ONE_HOT_COLS')\n",
    "    append_cols = [col for col in modeling_cols if col not in df_cols]\n",
    "    df.loc[:, append_cols] = 0\n",
    "logs.mid('ONE_HOT', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4a8f5736555b][2024-03-25 19:30:46.375976]   인입선 데이터 전처리 후 모델링 데이터 셋 크기: (14860, 103)\n",
      "[4a8f5736555b][2024-03-25 19:30:46.376238] 인입선 데이터 전처리 종료, 최종 처리시간: 0:04:46.160362\n"
     ]
    }
   ],
   "source": [
    "# 공사비별 인입선 데이터 합산\n",
    "unique_cons_ids = df.CONS_ID.unique()\n",
    "cons_id_sl_sums = []\n",
    "sum_cols = df.columns.tolist()[2:]\n",
    "for cid in unique_cons_ids:\n",
    "    _df = df[df.CONS_ID==cid]\n",
    "    sl_sums = _df[sum_cols].sum().values.tolist()\n",
    "    # sl_comp_id_cnt = _df.COMP_ID.nunique()\n",
    "    cons_id_sl_sums.append(\n",
    "        [cid, _df.shape[0]] + sl_sums)\n",
    "        # [cid, sl_comp_id_cnt, _df.shape[0]] + sl_sums)\n",
    "# 데이터프레임 만들기\n",
    "sl_sums_df = pd.DataFrame(\n",
    "    cons_id_sl_sums, \n",
    "    columns=['CONS_ID', 'REAL_SL_CNT', 'SL_SPAN_SUM'] \\\n",
    "        + sum_cols[1:]\n",
    ")\n",
    "\n",
    "# 공사비 데이터와 인입선 그룹 데이터 병합\n",
    "ppdf = pd.merge(\n",
    "    self.ppdf, sl_sums_df,\n",
    "    left_on='CONS_ID', right_on='CONS_ID', how='left'\n",
    ")\n",
    "logs.mid('RESULT', ppdf.shape)\n",
    "\n",
    "self.ppdf = ppdf\n",
    "logs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 완료시점에서 NaN값을 0으로 처리\n",
    "# 온라인 작업 시 인입선이 없거나 전주가 없는 작업 등에서 NaN가 올 수 있음\n",
    "self.ppdf.fillna(0, inplace=True)\n",
    "# 모델링 시점과 서비스 시점의 데이터프레임 컬럼 순서를 동일하게 하기 위해\n",
    "# 모델링 시점의 컬럼 순서를 저장해 서비스 시점에서 컬럼 순서를 재배치\n",
    "# One-Hot Encoding시점에 데이터 컬럼의 순서가 변경될 수 있음.\n",
    "if self.is_modeling:\n",
    "    last_pp_cols = self.ppdf.columns\n",
    "    save_data(last_pp_cols, fcode='DUMP,LAST_PP_COLS')\n",
    "else:\n",
    "    last_pp_cols = read_data('DUMP,LAST_PP_COLS')\n",
    "    self.ppdf = self.ppdf.reindex(columns=last_pp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14860, 103)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.ppdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CONS_ID', 'TOTAL_CONS_COST', 'LAST_MOD_DATE', 'OFFICE_NAME',\n",
       "       'CONT_CAP', 'YEAR', 'MONTH', 'DAY', 'DAYOFWEEK', 'DAYOFYEAR',\n",
       "       ...\n",
       "       'SL_SPEC_16.0', 'SL_SPEC_22.0', 'SL_SPEC_25.0', 'SL_SPEC_35.0',\n",
       "       'SL_SPEC_38.0', 'SL_SPEC_60.0', 'SL_SPEC_70.0', 'SL_SPEC_100.0',\n",
       "       'SL_SPEC_120.0', 'SL_SPEC_240.0'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.ppdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CONS_ID', 'TOTAL_CONS_COST', 'LAST_MOD_DATE', 'OFFICE_NAME',\n",
       "       'CONT_CAP', 'YEAR', 'MONTH', 'DAY', 'DAYOFWEEK', 'DAYOFYEAR',\n",
       "       ...\n",
       "       'SL_SPEC_16.0', 'SL_SPEC_22.0', 'SL_SPEC_25.0', 'SL_SPEC_35.0',\n",
       "       'SL_SPEC_38.0', 'SL_SPEC_60.0', 'SL_SPEC_70.0', 'SL_SPEC_100.0',\n",
       "       'SL_SPEC_120.0', 'SL_SPEC_240.0'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_pp_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t213p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
